"""
ì‹¤ì‹œê°„ YOLO ê²€ì¶œ ì—”ì§„ (ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œ)
Streamlit UIì™€ ë…ë¦½ì ìœ¼ë¡œ ì‹¤í–‰ë˜ëŠ” ê²€ì¶œ ì‹œìŠ¤í…œ
ì–¼êµ´ ë¶„ì„ ê¸°ëŠ¥ í†µí•© (MediaPipe Face Mesh)
"""

import cv2
import numpy as np
import time
import threading
import queue
from datetime import datetime
from ultralytics import YOLO
import platform
import requests
import json

# ì¹´ë©”ë¼ ì†ŒìŠ¤ ê´€ë¦¬ì ì„í¬íŠ¸
try:
    from camera_utils import CameraSourceManager, CameraSourceType
    CAMERA_UTILS_AVAILABLE = True
    print("[RealtimeDetector] âœ… CameraSourceManager ë¡œë“œ ì™„ë£Œ")
except ImportError:
    CAMERA_UTILS_AVAILABLE = False
    print("[RealtimeDetector] âš ï¸  CameraSourceManager ì—†ìŒ - ê¸°ë³¸ ì¹´ë©”ë¼ë§Œ ì§€ì›")

# ì–¼êµ´ ë¶„ì„ê¸° ì„í¬íŠ¸ (ì„ íƒì )
try:
    from face_analyzer import FaceAnalyzer
    FACE_ANALYZER_AVAILABLE = True
    print("[RealtimeDetector] âœ… FaceAnalyzer ëª¨ë“ˆ ë¡œë“œ ì™„ë£Œ")
except ImportError:
    FACE_ANALYZER_AVAILABLE = False
    print("[RealtimeDetector] âš ï¸  FaceAnalyzer ëª¨ë“ˆ ì—†ìŒ - ì–¼êµ´ ë¶„ì„ ë¹„í™œì„±í™”")


class RealtimeDetector:
    """
    ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰ë˜ëŠ” ì‹¤ì‹œê°„ YOLO ê²€ì¶œê¸°
    íë¥¼ ì‚¬ìš©í•˜ì—¬ Streamlit UIì™€ í†µì‹ 
    """
    
    def __init__(self, config, roi_regions):
        """
        Args:
            config: ì„¤ì • ë”•ì…”ë„ˆë¦¬
            roi_regions: ROI ì˜ì—­ ë¦¬ìŠ¤íŠ¸
        """
        self.config = config
        self.roi_regions = roi_regions
        
        # YOLO ëª¨ë¸ ë¡œë“œ
        model_path = config.get('yolo_model', 'yolov8n.pt')
        print(f"[RealtimeDetector] YOLO ëª¨ë¸ ë¡œë”©: {model_path}")
        self.model = YOLO(model_path)
        
        # ì¹´ë©”ë¼ ì´ˆê¸°í™”
        self.camera_source = config.get('camera_source', 0)
        self.camera_source_type = config.get('camera_source_type', None)  # ìë™ ê°ì§€ ê°€ëŠ¥
        self.cap = None
        
        # ì¹´ë©”ë¼ ì†ŒìŠ¤ ì •ë³´ ì¶œë ¥
        if CAMERA_UTILS_AVAILABLE:
            source_info = CameraSourceManager.get_source_info(self.camera_source)
            print(f"[RealtimeDetector] ì¹´ë©”ë¼ ì†ŒìŠ¤: {source_info['description']}")
            print(f"[RealtimeDetector] ì†ŒìŠ¤ íƒ€ì…: {source_info['source_type']}")
        
        # Linux í™˜ê²½ ê°ì§€
        self.is_linux = platform.system() == 'Linux'
        
        # ROIë³„ ìƒíƒœ ì¶”ì 
        self.roi_states = {}
        for roi in roi_regions:
            roi_id = roi['id']
            self.roi_states[roi_id] = {
                'person_detected': False,
                'detection_start_time': None,
                'absence_start_time': None,
                'last_status_sent': None,
                'detection_count': 0,
                'last_count_time': time.time()
            }
        
        # ì„¤ì •ê°’
        self.presence_threshold = config.get('presence_threshold_seconds', 5)
        self.absence_threshold = config.get('absence_threshold_seconds', 3)
        self.confidence_threshold = config.get('confidence_threshold', 0.5)
        self.person_class_id = 0  # COCO dataset person class
        
        # ê²€ì¶œ ê°„ê²© ì„¤ì • (ì´ˆ ë‹¨ìœ„)
        self.detection_interval = config.get('detection_interval_seconds', 1.0)  # ê¸°ë³¸ 1ì´ˆ
        self.last_detection_time = 0
        self.last_detections = []  # ë§ˆì§€ë§‰ ê²€ì¶œ ê²°ê³¼ ì €ì¥
        
        # ì–¼êµ´ ë¶„ì„ ì„¤ì •
        self.enable_face_analysis = config.get('enable_face_analysis', False)
        self.face_analysis_roi_only = config.get('face_analysis_roi_only', True)
        self.face_analyzer = None
        self.last_face_results = {}  # ë§ˆì§€ë§‰ ì–¼êµ´ ë¶„ì„ ê²°ê³¼ ì €ì¥
        
        if self.enable_face_analysis and FACE_ANALYZER_AVAILABLE:
            try:
                self.face_analyzer = FaceAnalyzer()
                print("[RealtimeDetector] âœ… FaceAnalyzer ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                print(f"[RealtimeDetector] âš ï¸  FaceAnalyzer ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self.enable_face_analysis = False
        elif self.enable_face_analysis and not FACE_ANALYZER_AVAILABLE:
            print("[RealtimeDetector] âš ï¸  FaceAnalyzer ëª¨ë“ˆ ì—†ìŒ - ì–¼êµ´ ë¶„ì„ ë¹„í™œì„±í™”")
            self.enable_face_analysis = False
        
        # ìŠ¤ë ˆë“œ ì œì–´
        self.running = False
        self.thread = None
        
        # í”„ë ˆì„ ë° ìƒíƒœ í (Streamlitê³¼ í†µì‹ )
        self.frame_queue = queue.Queue(maxsize=2)  # ìµœëŒ€ 2ê°œ í”„ë ˆì„ë§Œ ë²„í¼ë§
        self.original_frame_queue = queue.Queue(maxsize=2)  # ì›ë³¸ í”„ë ˆì„ í (ROI/ë¼ë²¨ ì—†ìŒ)
        self.stats_queue = queue.Queue(maxsize=10)
        self.event_queue = queue.Queue(maxsize=50)
        
        # FPS ì¸¡ì •
        self.fps = 0
        self.frame_count = 0
        self.fps_start_time = time.time()
        
        # API ì„¤ì •
        self.api_endpoint = config.get('api_endpoint', '')
        self.api_enabled = bool(self.api_endpoint)
        
        # ì‹¤ì‹œê°„ API ì „ì†¡ ìƒíƒœ ì¶”ì 
        self.last_sad_api_time = {}  # ROIë³„ ë§ˆì§€ë§‰ SAD API ì „ì†¡ ì‹œê°„
        self.sad_api_cooldown = 10  # SAD API ì¬ì „ì†¡ ëŒ€ê¸° ì‹œê°„ (ì´ˆ)
        
        print("[RealtimeDetector] ì´ˆê¸°í™” ì™„ë£Œ")
        if self.api_enabled:
            print(f"[RealtimeDetector] API ì—”ë“œí¬ì¸íŠ¸: {self.api_endpoint}")
    
    def is_person_in_polygon_roi(self, bbox, roi):
        """ì‚¬ëŒì´ ROI ë‚´ì— ìˆëŠ”ì§€ í™•ì¸"""
        x1, y1, x2, y2 = bbox
        center_x = (x1 + x2) / 2
        center_y = (y1 + y2) / 2
        center_point = (int(center_x), int(center_y))
        
        if roi.get('type') == 'polygon' and 'points' in roi:
            points = np.array(roi['points'], dtype=np.int32)
            result = cv2.pointPolygonTest(points, center_point, False)
            return result >= 0
        
        return False
    
    def send_realtime_api(self, roi_id, event_type, reason, frame=None):
        """ì‹¤ì‹œê°„ API ì „ì†¡ (SAD í‘œì •, ë¶€ì¬ ìƒíƒœ) - í˜„ì¬ ìŠ¤ëƒ…ìƒ· ì´ë¯¸ì§€ í¬í•¨"""
        if not self.api_enabled:
            return
        
        try:
            import uuid
            import base64
            from io import BytesIO
            
            # UUID ìƒì„±
            event_id = str(uuid.uuid4())
            
            # FCM Message ID ìƒì„±
            fcm_project = self.config.get('fcm_project_id', 'emergency-alert-system-f27e6')
            fcm_message_id = f"projects/{fcm_project}/messages/{int(time.time() * 1000)}"
            
            # API í˜ì´ë¡œë“œ ìƒì„± (ìš”ì²­í•œ í˜•ì‹)
            payload = {
                'eventId': event_id,
                'fcmMessageId': fcm_message_id,
                'imageUrl': None,
                'status': 'SENT',
                'createdAt': datetime.now().isoformat(),
                'watchId': self.config.get('watch_id', 'unknown'),
                'senderId': self.config.get('sender_id', 'test-user'),
                'note': self.config.get('note', 'ì‘ê¸‰ìƒí™© ë©”ì‹œì§€')
            }
            
            print(f"[RealtimeDetector] ğŸš¨ ì‹¤ì‹œê°„ API ì „ì†¡: {roi_id} - {reason}")
            
            # ì´ë¯¸ì§€ê°€ ìˆìœ¼ë©´ multipart/form-dataë¡œ ì „ì†¡
            if frame is not None:
                # í”„ë ˆì„ì„ JPEGë¡œ ì¸ì½”ë”©
                _, buffer = cv2.imencode('.jpg', frame, [cv2.IMWRITE_JPEG_QUALITY, 85])
                image_bytes = BytesIO(buffer.tobytes())
                
                # Multipart form data ìƒì„±
                files = {
                    'image': ('snapshot.jpg', image_bytes, 'image/jpeg')
                }
                
                # Form data (JSON ë°ì´í„°ë¥¼ form fieldë¡œ)
                form_data = {
                    'eventId': payload['eventId'],
                    'fcmMessageId': payload['fcmMessageId'],
                    'status': payload['status'],
                    'createdAt': payload['createdAt'],
                    'watchId': payload['watchId'],
                    'senderId': payload['senderId'],
                    'note': payload['note']
                }
                
                # API ì „ì†¡ (multipart/form-data)
                response = requests.post(
                    self.api_endpoint,
                    data=form_data,
                    files=files,
                    timeout=10
                )
            else:
                # ì´ë¯¸ì§€ ì—†ìœ¼ë©´ JSONìœ¼ë¡œ ì „ì†¡
                response = requests.post(
                    self.api_endpoint,
                    json=payload,
                    headers={'Content-Type': 'application/json'},
                    timeout=10
                )
            
            if response.status_code in [200, 201]:
                print(f"[RealtimeDetector] âœ… API ì „ì†¡ ì„±ê³µ: {response.status_code}")
                print(f"[RealtimeDetector] ğŸ“¤ ì „ì†¡ëœ ë°ì´í„°: {payload}")
            else:
                print(f"[RealtimeDetector] âš ï¸ API ì‘ë‹µ ì˜¤ë¥˜: {response.status_code}")
                print(f"[RealtimeDetector] ì‘ë‹µ ë‚´ìš©: {response.text}")
                
        except requests.exceptions.Timeout:
            print(f"[RealtimeDetector] â±ï¸ API íƒ€ì„ì•„ì›ƒ")
        except requests.exceptions.ConnectionError:
            print(f"[RealtimeDetector] âŒ API ì—°ê²° ì‹¤íŒ¨")
        except Exception as e:
            print(f"[RealtimeDetector] âŒ API ì „ì†¡ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
    
    def update_roi_state(self, roi_id, person_in_roi, frame=None):
        """ROI ìƒíƒœ ì—…ë°ì´íŠ¸ ë° API ì´ë²¤íŠ¸ ì „ì†¡ íŒë‹¨"""
        state = self.roi_states[roi_id]
        current_time = time.time()
        
        if person_in_roi:
            # ì‚¬ëŒ ê²€ì¶œë¨
            if not state['person_detected']:
                # ì²˜ìŒ ê²€ì¶œëœ ê²½ìš°
                state['person_detected'] = True
                state['detection_start_time'] = current_time
                state['absence_start_time'] = None
            else:
                # ê³„ì† ê²€ì¶œ ì¤‘
                detection_duration = current_time - state['detection_start_time']
                
                # Presence threshold ì´ˆê³¼ ì‹œ ì´ë²¤íŠ¸ ì „ì†¡
                if detection_duration >= self.presence_threshold:
                    if state['last_status_sent'] != 'present':
                        state['last_status_sent'] = 'present'
                        state['detection_count'] += 1
                        
                        # ì´ë²¤íŠ¸ íì— ì „ì†¡
                        self.event_queue.put({
                            'timestamp': datetime.now().strftime('%H:%M:%S'),
                            'roi_id': roi_id,
                            'status': 'present',
                            'count': state['detection_count']
                        })
        else:
            # ì‚¬ëŒ ë¯¸ê²€ì¶œ
            if state['person_detected']:
                # ì´ì „ì— ê²€ì¶œë˜ì—ˆë‹¤ê°€ ì‚¬ë¼ì§„ ê²½ìš°
                state['person_detected'] = False
                state['absence_start_time'] = current_time
                state['detection_start_time'] = None
            elif state['absence_start_time'] is not None:
                # ê³„ì† ë¯¸ê²€ì¶œ ì¤‘
                absence_duration = current_time - state['absence_start_time']
                
                # Absence threshold ì´ˆê³¼ ì‹œ ì´ë²¤íŠ¸ ì „ì†¡
                if absence_duration >= self.absence_threshold:
                    if state['last_status_sent'] == 'present':
                        state['last_status_sent'] = 'absent'
                        
                        # ğŸš¨ ì‹¤ì‹œê°„ API ì „ì†¡ (ë¶€ì¬ ìƒíƒœ) - í˜„ì¬ í”„ë ˆì„ í¬í•¨
                        self.send_realtime_api(
                            roi_id=roi_id,
                            event_type='absent',
                            reason='Person absence detected',
                            frame=frame
                        )
                        
                        # ì´ë²¤íŠ¸ íì— ì „ì†¡
                        self.event_queue.put({
                            'timestamp': datetime.now().strftime('%H:%M:%S'),
                            'roi_id': roi_id,
                            'status': 'absent',
                            'count': state['detection_count']
                        })
        
        # ìƒíƒœ í ì—…ë°ì´íŠ¸
        try:
            self.stats_queue.put_nowait({
                'roi_id': roi_id,
                'status': state['last_status_sent'] or 'None',
                'count': state['detection_count'],
                'person_detected': state['person_detected']
            })
        except queue.Full:
            pass  # íê°€ ê°€ë“ ì°¨ë©´ ë¬´ì‹œ
    
    def draw_rois_and_detections(self, frame, detections):
        """í”„ë ˆì„ì— ROIì™€ ê²€ì¶œ ê²°ê³¼ ê·¸ë¦¬ê¸° (ì–¼êµ´ ë¶„ì„ ê²°ê³¼ í¬í•¨)"""
        frame_copy = frame.copy()
        
        # ROI ê·¸ë¦¬ê¸°
        for roi in self.roi_regions:
            roi_id = roi['id']
            state = self.roi_states[roi_id]
            
            # ìƒíƒœì— ë”°ë¥¸ ìƒ‰ìƒ
            color = (0, 255, 0) if state['person_detected'] else (0, 0, 255)
            
            if roi.get('type') == 'polygon' and 'points' in roi:
                points = np.array(roi['points'], dtype=np.int32)
                
                # ë°˜íˆ¬ëª… ì±„ìš°ê¸°
                overlay = frame_copy.copy()
                cv2.fillPoly(overlay, [points], color)
                cv2.addWeighted(overlay, 0.2, frame_copy, 0.8, 0, frame_copy)
                
                # í…Œë‘ë¦¬
                cv2.polylines(frame_copy, [points], True, color, 2)
                
                # ROI ID
                M = cv2.moments(points)
                if M["m00"] != 0:
                    cx = int(M["m10"] / M["m00"])
                    cy = int(M["m01"] / M["m00"])
                    
                    cv2.putText(frame_copy, roi_id, (cx - 30, cy - 20),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 3)
                    cv2.putText(frame_copy, roi_id, (cx - 30, cy - 20),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)
                    
                    # ìƒíƒœ í‘œì‹œ
                    status_text = f"{state['last_status_sent'] or 'None'}"
                    cv2.putText(frame_copy, status_text, (cx - 30, cy + 10),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
                    
                    # ì¹´ìš´íŠ¸
                    count_text = f"Count: {state['detection_count']}"
                    cv2.putText(frame_copy, count_text, (cx - 30, cy + 30),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 2)
        
        # ê²€ì¶œëœ ì‚¬ëŒ ë°”ìš´ë”© ë°•ìŠ¤ + ì–¼êµ´ ë¶„ì„ ê²°ê³¼
        for detection in detections:
            x1, y1, x2, y2 = map(int, detection['bbox'])
            conf = detection['confidence']
            
            # ì‚¬ëŒ BBox
            cv2.rectangle(frame_copy, (x1, y1), (x2, y2), (255, 0, 0), 2)
            
            # ì–¼êµ´ ë¶„ì„ ê²°ê³¼ í‘œì‹œ
            face_result = self.last_face_results.get(tuple(detection['bbox']))
            
            if face_result and face_result.get('face_detected'):
                # í‘œì • ì •ë³´ ì¶”ì¶œ (ë”•ì…”ë„ˆë¦¬ ì²˜ë¦¬)
                expr_info = face_result.get('expression', {})
                if isinstance(expr_info, dict):
                    expr_text = f"{expr_info.get('expression', 'unknown')} ({expr_info.get('confidence', 0):.2f})"
                else:
                    expr_text = str(expr_info)
                
                # í…ìŠ¤íŠ¸ ì¤€ë¹„
                info_lines = [
                    f"Person {conf:.2f}",
                    f"Eyes: {'Open' if face_result['eyes_open'] else 'Closed'}",
                    f"Mouth: {face_result['mouth_state']}",
                    f"Expr: {expr_text}",
                ]
                
                if face_result.get('has_mask_or_ventilator'):
                    info_lines.append(f"Mask/Ventilator: Yes ({face_result['device_confidence']:.2f})")
                
                # í…ìŠ¤íŠ¸ ë°°ê²½ ë° í‘œì‹œ
                text_y = y1 - 10
                for i, line in enumerate(info_lines):
                    text_y_pos = text_y - (len(info_lines) - i - 1) * 20
                    
                    # ë°°ê²½ ì‚¬ê°í˜•
                    (text_width, text_height), _ = cv2.getTextSize(
                        line, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2
                    )
                    cv2.rectangle(
                        frame_copy, 
                        (x1, text_y_pos - text_height - 2), 
                        (x1 + text_width + 5, text_y_pos + 2),
                        (0, 0, 0), -1
                    )
                    
                    # í…ìŠ¤íŠ¸
                    cv2.putText(
                        frame_copy, line, (x1, text_y_pos),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2
                    )
            else:
                # ì–¼êµ´ ë¶„ì„ ì—†ì„ ë•ŒëŠ” ê¸°ë³¸ í‘œì‹œ
                cv2.putText(frame_copy, f'Person {conf:.2f}', (x1, y1 - 10),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)
        
        # FPS ë° ê²€ì¶œ ê°„ê²© í‘œì‹œ
        cv2.putText(frame_copy, f'Display FPS: {self.fps:.1f}', (10, 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        cv2.putText(frame_copy, f'YOLO: Every {self.detection_interval}s', (10, 60),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)
        
        # ì–¼êµ´ ë¶„ì„ í™œì„±í™” í‘œì‹œ
        if self.enable_face_analysis:
            mode_text = "Face: ON (ROI Only)" if self.face_analysis_roi_only else "Face: ON (All)"
            cv2.putText(frame_copy, mode_text, (10, 90),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 255), 2)
        
        return frame_copy
    
    def process_frame(self, frame=None):
        """ë‹¨ì¼ í”„ë ˆì„ ì²˜ë¦¬ (YOLO ì¶”ë¡ ì€ ì„¤ì •ëœ ê°„ê²©ë§ˆë‹¤ë§Œ ìˆ˜í–‰)"""
        # í”„ë ˆì„ì´ ì œê³µë˜ì§€ ì•Šìœ¼ë©´ ì¹´ë©”ë¼ì—ì„œ ì½ê¸°
        if frame is None:
            ret, frame = self.cap.read()
            if not ret:
                return None
        
        current_time = time.time()
        detections = []
        
        # YOLO ì¶”ë¡ ì„ ì„¤ì •ëœ ê°„ê²©(ê¸°ë³¸ 1ì´ˆ)ë§ˆë‹¤ë§Œ ìˆ˜í–‰
        if current_time - self.last_detection_time >= self.detection_interval:
            print(f"[RealtimeDetector] YOLO ì¶”ë¡  ì‹¤í–‰ (ê°„ê²©: {self.detection_interval}ì´ˆ)")
            
            # YOLO ì¶”ë¡  (NumPy í˜¸í™˜ì„± ê°œì„ )
            try:
                # NumPy ë°°ì—´ì„ ëª…ì‹œì ìœ¼ë¡œ contiguousí•˜ê²Œ ë³€í™˜
                frame_input = np.ascontiguousarray(frame)
                results = self.model(frame_input, verbose=False)
            except RuntimeError as e:
                print(f"[RealtimeDetector] âš ï¸  YOLO ì¶”ë¡  ì‹¤íŒ¨: {e}")
                # í”„ë ˆì„ì„ ë³µì‚¬í•˜ì—¬ ì¬ì‹œë„
                frame_input = frame.copy()
                results = self.model(frame_input, verbose=False)
            
            # ê²€ì¶œëœ ì‚¬ëŒë“¤
            detections = []
            
            # ê° ROI í™•ì¸
            for roi in self.roi_regions:
                roi_id = roi['id']
                person_in_roi = False
                
                for result in results:
                    boxes = result.boxes
                    for box in boxes:
                        cls = int(box.cls[0])
                        conf = float(box.conf[0])
                        
                        if cls == self.person_class_id and conf >= self.confidence_threshold:
                            # NumPy ë³€í™˜ ì•ˆì „ì„± ê°œì„ 
                            try:
                                bbox = box.xyxy[0].cpu().numpy()
                            except:
                                bbox = np.array(box.xyxy[0].cpu())
                            
                            detections.append({
                                'bbox': bbox,
                                'confidence': conf
                            })
                            
                            if self.is_person_in_polygon_roi(bbox, roi):
                                person_in_roi = True
            
            # ì–¼êµ´ ë¶„ì„ (ì˜µì…˜)
            face_analysis_results = {}
            if self.enable_face_analysis and self.face_analyzer:
                print(f"[RealtimeDetector] ì–¼êµ´ ë¶„ì„ ì‹¤í–‰ ({len(detections)}ëª… ê²€ì¶œ)")
                
                for detection in detections:
                    bbox = detection['bbox']
                    
                    # ROI ë‚´ë¶€ ì‚¬ëŒë§Œ ë¶„ì„ ì˜µì…˜
                    if self.face_analysis_roi_only:
                        person_in_any_roi = False
                        for roi in self.roi_regions:
                            if self.is_person_in_polygon_roi(bbox, roi):
                                person_in_any_roi = True
                                break
                        
                        if not person_in_any_roi:
                            continue  # ROI ë°–ì´ë©´ ê±´ë„ˆë›°ê¸°
                    
                    # ì–¼êµ´ ë¶„ì„ ìˆ˜í–‰
                    try:
                        face_result = self.face_analyzer.analyze_face(frame, bbox)
                        if face_result:
                            face_analysis_results[tuple(bbox)] = face_result
                            
                            # í‘œì • ì •ë³´ ì¶”ì¶œ (ë”•ì…”ë„ˆë¦¬ ì²˜ë¦¬)
                            expr_info = face_result.get('expression', {})
                            if isinstance(expr_info, dict):
                                expression = expr_info.get('expression', 'unknown')
                                confidence = expr_info.get('confidence', 0)
                                expr_text = f"{expression} ({confidence:.2f})"
                            else:
                                expression = 'unknown'
                                expr_text = str(expr_info)
                            
                            print(f"[RealtimeDetector] âœ… ì–¼êµ´ ë¶„ì„ ì™„ë£Œ: Eyes={'Open' if face_result['eyes_open'] else 'Closed'}, Mouth={face_result['mouth_state']}, Expression={expr_text}")
                            
                            # ğŸš¨ SAD í‘œì • ê°ì§€ ì‹œ ì‹¤ì‹œê°„ API ì „ì†¡
                            if expression == 'sad' and confidence > 0.6:
                                # ì–´ëŠ ROIì— ì†í•˜ëŠ”ì§€ í™•ì¸
                                person_roi = None
                                for roi in self.roi_regions:
                                    if self.is_person_in_polygon_roi(bbox, roi):
                                        person_roi = roi['id']
                                        break
                                
                                if person_roi:
                                    # Cooldown ì²´í¬ (ê°™ì€ ROIì—ì„œ 10ì´ˆ ë‚´ ì¤‘ë³µ ì „ì†¡ ë°©ì§€)
                                    last_sad_time = self.last_sad_api_time.get(person_roi, 0)
                                    if current_time - last_sad_time >= self.sad_api_cooldown:
                                        self.send_realtime_api(
                                            roi_id=person_roi,
                                            event_type='sad_expression',
                                            reason=f'SAD expression detected (confidence: {confidence:.2f})',
                                            frame=frame
                                        )
                                        self.last_sad_api_time[person_roi] = current_time
                    except Exception as e:
                        print(f"[RealtimeDetector] âš ï¸  ì–¼êµ´ ë¶„ì„ ì‹¤íŒ¨: {e}")
            
            # ì–¼êµ´ ë¶„ì„ ê²°ê³¼ ì €ì¥
            self.last_face_results = face_analysis_results
            
            # ROI ìƒíƒœ ì—…ë°ì´íŠ¸ (í˜„ì¬ í”„ë ˆì„ ì „ë‹¬)
            self.update_roi_state(roi_id, person_in_roi, frame=frame)
            
            # ê²€ì¶œ ê²°ê³¼ ì €ì¥ (ë‹¤ìŒ í”„ë ˆì„ë“¤ì—ì„œ ì¬ì‚¬ìš©)
            self.last_detections = detections
            self.last_detection_time = current_time
        else:
            # ì´ì „ ê²€ì¶œ ê²°ê³¼ ì¬ì‚¬ìš© (YOLO ì¶”ë¡  ìƒëµ)
            detections = self.last_detections
        
        # ì‹œê°í™” (ë§¤ í”„ë ˆì„ë§ˆë‹¤ ìˆ˜í–‰ - ë¶€ë“œëŸ¬ìš´ ì˜ìƒ)
        annotated_frame = self.draw_rois_and_detections(frame, detections)
        
        # FPS ê³„ì‚° (í™”ë©´ FPS)
        self.frame_count += 1
        elapsed_time = time.time() - self.fps_start_time
        if elapsed_time > 1.0:
            self.fps = self.frame_count / elapsed_time
            self.frame_count = 0
            self.fps_start_time = time.time()
        
        return annotated_frame
    
    def run(self):
        """ë°±ê·¸ë¼ìš´ë“œ ê²€ì¶œ ë£¨í”„"""
        print("[RealtimeDetector] ê²€ì¶œ ì‹œì‘")
        
        # ì¹´ë©”ë¼ ì—´ê¸° (CameraSourceManager ì‚¬ìš©)
        if CAMERA_UTILS_AVAILABLE:
            print(f"[RealtimeDetector] CameraSourceManagerë¡œ ì¹´ë©”ë¼ ì—´ê¸°")
            
            # ì¶”ê°€ ì˜µì…˜ ì„¤ì •
            camera_options = {}
            if self.is_linux and isinstance(self.camera_source, int):
                camera_options['backend'] = cv2.CAP_V4L2
            
            self.cap = CameraSourceManager.open_camera(
                self.camera_source, 
                self.camera_source_type,
                **camera_options
            )
        else:
            # ê¸°ë³¸ ë°©ì‹ (í•˜ìœ„ í˜¸í™˜ì„±)
            print(f"[RealtimeDetector] ê¸°ë³¸ ë°©ì‹ìœ¼ë¡œ ì¹´ë©”ë¼ ì—´ê¸°")
            if self.is_linux and isinstance(self.camera_source, int):
                self.cap = cv2.VideoCapture(self.camera_source, cv2.CAP_V4L2)
                print(f"[RealtimeDetector] Linux: V4L2 ë°±ì—”ë“œë¡œ ì¹´ë©”ë¼ {self.camera_source} ì—´ê¸°")
            else:
                self.cap = cv2.VideoCapture(self.camera_source)
        
        if not self.cap or not self.cap.isOpened():
            print(f"[RealtimeDetector] âŒ ì¹´ë©”ë¼ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.camera_source}")
            return
        
        print("[RealtimeDetector] âœ… ì¹´ë©”ë¼ ì—´ë¦¼ ì„±ê³µ")
        
        while self.running:
            # ì›ë³¸ í”„ë ˆì„ ì½ê¸°
            ret, original_frame = self.cap.read()
            if not ret or original_frame is None:
                print("[RealtimeDetector] í”„ë ˆì„ ì½ê¸° ì‹¤íŒ¨")
                break
            
            # í”„ë ˆì„ ì²˜ë¦¬ (ê²€ì¶œ ë° ì‹œê°í™”)
            annotated_frame = self.process_frame(original_frame)
            
            if annotated_frame is None:
                continue
            
            # ì‹œê°í™”ëœ í”„ë ˆì„ íì— ì „ì†¡ (UI í‘œì‹œìš©)
            try:
                self.frame_queue.put_nowait(annotated_frame)
            except queue.Full:
                # íê°€ ê°€ë“ ì°¨ë©´ ì˜¤ë˜ëœ í”„ë ˆì„ ì œê±° í›„ ìƒˆ í”„ë ˆì„ ì¶”ê°€
                try:
                    self.frame_queue.get_nowait()
                    self.frame_queue.put_nowait(annotated_frame)
                except:
                    pass
            
            # ì›ë³¸ í”„ë ˆì„ íì— ì „ì†¡ (í…ŒìŠ¤íŠ¸ API ì „ì†¡ìš© - ìˆœìˆ˜ ì¹´ë©”ë¼ ì´ë¯¸ì§€)
            try:
                self.original_frame_queue.put_nowait(original_frame.copy())
            except queue.Full:
                # íê°€ ê°€ë“ ì°¨ë©´ ì˜¤ë˜ëœ í”„ë ˆì„ ì œê±° í›„ ìƒˆ í”„ë ˆì„ ì¶”ê°€
                try:
                    self.original_frame_queue.get_nowait()
                    self.original_frame_queue.put_nowait(original_frame.copy())
                except:
                    pass
        
        self.cap.release()
        print("[RealtimeDetector] ê²€ì¶œ ì¢…ë£Œ")
    
    def start(self):
        """ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œ ì‹œì‘"""
        if not self.running:
            self.running = True
            self.thread = threading.Thread(target=self.run, daemon=True)
            self.thread.start()
            print("[RealtimeDetector] ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œ ì‹œì‘ë¨")
    
    def stop(self):
        """ê²€ì¶œ ì¤‘ì§€"""
        self.running = False
        if self.thread:
            self.thread.join(timeout=2)
        print("[RealtimeDetector] ì¤‘ì§€ë¨")
    
    def get_latest_frame(self, original=False):
        """
        ìµœì‹  í”„ë ˆì„ ê°€ì ¸ì˜¤ê¸° (ë…¼ë¸”ë¡œí‚¹)
        
        Args:
            original: Trueë©´ ì›ë³¸ í”„ë ˆì„ (ROI/ë¼ë²¨ ì—†ìŒ), Falseë©´ ì‹œê°í™”ëœ í”„ë ˆì„
        """
        try:
            if original:
                return self.original_frame_queue.get_nowait()
            else:
                return self.frame_queue.get_nowait()
        except queue.Empty:
            return None
    
    def get_latest_stats(self):
        """ìµœì‹  í†µê³„ ê°€ì ¸ì˜¤ê¸° (ë…¼ë¸”ë¡œí‚¹)"""
        stats = []
        try:
            while True:
                stats.append(self.stats_queue.get_nowait())
        except queue.Empty:
            pass
        return stats
    
    def get_latest_events(self):
        """ìµœì‹  ì´ë²¤íŠ¸ ê°€ì ¸ì˜¤ê¸° (ë…¼ë¸”ë¡œí‚¹)"""
        events = []
        try:
            while True:
                events.append(self.event_queue.get_nowait())
        except queue.Empty:
            pass
        return events
